## ä»‹ç»
æœ¬æ–‡å°†ä»‹ç»æˆ‘æ˜¯å¦‚ä½•åœ¨pythonçˆ¬è™«é‡Œé¢ä¸€æ­¥ä¸€æ­¥è¸©å‘ï¼Œç„¶åæ…¢æ…¢èµ°å‡ºæ¥çš„ï¼ŒæœŸé—´ç¢°åˆ°çš„æ‰€æœ‰é—®é¢˜æˆ‘éƒ½ä¼šè¯¦ç»†è¯´æ˜ï¼Œè®©å¤§å®¶ä»¥åç¢°åˆ°è¿™äº›é—®é¢˜æ—¶èƒ½å¤Ÿå¿«é€Ÿç¡®å®šé—®é¢˜çš„æ¥æºã€‚
## æµç¨‹ä¸€è§ˆ
é¦–å…ˆæˆ‘æ˜¯æƒ³çˆ¬æŸä¸ªç½‘ç«™ä¸Šé¢çš„æ‰€æœ‰æ–‡ç« å†…å®¹ï¼Œä½†æ˜¯ç”±äºä¹‹å‰æ²¡æœ‰åšè¿‡çˆ¬è™«ï¼ˆä¹Ÿä¸çŸ¥é“åˆ°åº•é‚£ä¸ªè¯­è¨€æœ€æ–¹ä¾¿ï¼‰ï¼Œæ‰€ä»¥è¿™é‡Œæƒ³åˆ°äº†æ˜¯ç”¨pythonæ¥åšä¸€ä¸ªçˆ¬è™«ï¼ˆæ¯•ç«Ÿäººå®¶çš„åå­—éƒ½å¸¦æœ‰çˆ¬è™«çš„å«ä¹‰ğŸ˜„ï¼‰ï¼Œæˆ‘è¿™è¾¹æ˜¯æ‰“ç®—å…ˆå°†æ‰€æœ‰ä»ç½‘ç«™ä¸Šçˆ¬ä¸‹æ¥çš„æ•°æ®æ”¾åˆ°`ElasticSearch`é‡Œé¢, é€‰æ‹©`ElasticSearch`çš„åŸå› æ˜¯é€Ÿåº¦å¿«ï¼Œé‡Œé¢åˆ†è¯æ’ä»¶ï¼Œå€’æ’ç´¢å¼•ï¼Œéœ€è¦æ•°æ®çš„æ—¶å€™æŸ¥è¯¢æ•ˆç‡ä¼šéå¸¸å¥½ï¼ˆæ¯•ç«Ÿçˆ¬çš„ä¸œè¥¿æ¯”è¾ƒå¤šğŸ˜„ï¼‰ï¼Œç„¶åæˆ‘ä¼šå°†æ‰€æœ‰çš„æ•°æ®åœ¨`ElasticSearch`çš„è€å©†`kibana`é‡Œé¢å°†æ•°æ®è¿›è¡Œå¯è§†åŒ–å‡ºæ¥ï¼Œå¹¶ä¸”åˆ†æè¿™äº›æ–‡ç« å†…å®¹ï¼Œå¯ä»¥å…ˆçœ‹ä¸€ä¸‹é¢„æœŸå¯è§†åŒ–çš„æ•ˆæœï¼ˆä¸Šå›¾äº†ï¼‰ï¼Œè¿™ä¸ªæ•ˆæœå›¾æ˜¯`kibana6.4`ç³»ç»Ÿç»™äºˆçš„å¸®åŠ©æ•ˆæœå›¾ï¼ˆå°±æ˜¯è¯´ä½ å¯ä»¥å¼„æˆè¿™æ ·,æˆ‘ä¹Ÿæƒ³å¼„æˆè¿™æ ·ğŸ˜ï¼‰ã€‚åé¢æˆ‘ä¼šå‘ä¸€ä¸ªdockerfileä¸Šæ¥ï¼ˆç°åœ¨è¿˜æ²¡å¼„ğŸ˜³ï¼‰ã€‚
![](http://uninote.com.cn/docs/1079089832/__pic/md685Bew.png)

## å¼„å®Œè¿™ä¸ªçˆ¬è™«ä¼šå­¦åˆ°é‚£äº›çŸ¥è¯†ç‚¹
å¦‚æœèƒ½æŒ‰ç…§æˆ‘çš„å…¥å‘å’Œå‡ºå‘ï¼Œä½ åº”è¯¥å¯ä»¥getåˆ°è¿™äº›ä¸œè¥¿ï¼Œè€Œä¸”è¿˜ä¼šçµæ´»çš„ä½¿ç”¨å®ƒï¼ˆå› ä¸ºä½ åœ¨å¼€å‘çš„æ—¶å€™ä¼šä¸€ç›´ä½¿ç”¨å®ƒä»¬å»è°ƒè¯•ï¼Œæ‰€ä»¥ä½ å°±ç”¨çš„6äº†ï¼‰
1. ElasticSearch çš„å®‰è£…åŠåŸºæœ¬ä½¿ç”¨(Mappingçš„å»ºç«‹ï¼Œæ•°æ®çš„æŸ¥æ‰¾ï¼Œä»¥åŠç´¢å¼•çš„åˆ é™¤ï¼Œå’Œç´¢å¼•æ•°æ®è¿ç§»)
2. Kibana çš„å®‰è£…å’Œä½¿ç”¨(kibanaçš„å¯è§†åŒ–ç•Œé¢åº”è¯¥é…ç½®é‚£äº›ä¸œè¥¿ï¼Œæ…¢æ…¢çš„ä¸€æ­¥ä¸€æ­¥è¾¾åˆ°å¼€ç¯‡çš„é‚£å¼ å›¾ç‰‡çš„æ•ˆæœ)
3. pythonçš„scrapyåº“çš„ä½¿ç”¨ä»¥åŠæ³¨æ„äº‹é¡¹
4. redisçš„å®‰è£…ä»¥åŠä½¿ç”¨(è¿™é‡Œé¢æˆ‘ç”¨redisæ¥å»é™¤é‡å¤é“¾æ¥ï¼Œscrapyæ˜¯è‡ªå¸¦å»é™¤é‡å¤é“¾æ¥çš„ï¼Œä½†æ˜¯å¦‚æœä½¿ç”¨è‡ªå¸¦çš„è¿‡æ»¤å±æ€§å°±æ²¡æ³•ä¸€ç›´è·‘å…¨ç½‘ç«™çš„é“¾æ¥äº†)

## ç¯å¢ƒéœ€æ±‚
1. Jdk (Elasticsearchéœ€è¦)
2. ElasticSearch (ç”¨æ¥å­˜å‚¨æ•°æ®)
3. Kinaba (ç”¨æ¥æ“ä½œElasticSearchå’Œæ•°æ®å¯è§†åŒ–)
4. Python (ç¼–å†™çˆ¬è™«)
5. Redis (æ•°æ®æ’é‡)

è¿™äº›ä¸œè¥¿å¯ä»¥å»æ‰¾ç›¸åº”çš„æ•™ç¨‹å®‰è£…ï¼Œæˆ‘è¿™é‡Œåªæœ‰ElasticSearchçš„å®‰è£…ğŸ˜¢[ç‚¹æˆ‘è·å–å®‰è£…æ•™ç¨‹](https://juejin.im/post/5c825c716fb9a049d4429ce6 "ç‚¹æˆ‘è·å–å®‰è£…æ•™ç¨‹")

## ç¬¬ä¸€æ­¥ï¼Œä½¿ç”¨pythonçš„pipæ¥å®‰è£…éœ€è¦çš„æ’ä»¶ï¼ˆç¬¬ä¸€ä¸ªå‘åœ¨è¿™å„¿ï¼‰
1. **tomd**:å°†htmlè½¬æ¢æˆmarkdown
```
pip3 install tomd
```
2. **redis**:éœ€è¦pythonçš„redisæ’ä»¶
```
pip3 install redis
```
3. **scrapy**:æ¡†æ¶å®‰è£…(å‘)
	1. é¦–å…ˆæˆ‘æ˜¯åƒä¸Šé¢ä¸€æ ·æ‰§è¡Œäº†
	```
	pip3 install scrapy
	```
	2. ç„¶åå‘ç°ç¼ºå°‘`gcc`ç»„ä»¶ `error: command 'gcc' failed with exit status 1`
	![](http://uninote.com.cn/docs/1079089832/__pic/QQvjl3tJ.png)
	3. ç„¶åæˆ‘å°±æ‰¾å•Šæ‰¾ï¼Œæ‰¾å•Šæ‰¾ï¼Œæœ€åç»ˆäºæ‰¾åˆ°äº†æ­£ç¡®çš„è§£å†³æ–¹æ³•(æœŸé—´è¯•äº†å¾ˆå¤šé”™è¯¯ç­”æ¡ˆğŸ˜­)ã€‚æœ€ç»ˆçš„è§£å†³åŠæ³•å°±æ˜¯ä½¿ç”¨`yum`æ¥å®‰è£…`python34-devel`,  è¿™ä¸ª`python34-devel`æ ¹æ®ä½ è‡ªå·±çš„pythonç‰ˆæœ¬æ¥ï¼Œå¯èƒ½æ˜¯python-devel,æ˜¯å¤šå°‘ç‰ˆæœ¬å°±å°†ä¸­é—´çš„34æ”¹æˆä½ çš„ç‰ˆæœ¬, æˆ‘çš„æ˜¯3.4.6
	```
	yum install python34-devel
	```
	4. å®‰è£…å®Œæˆè¿‡åä½¿ç”¨å‘½ä»¤ scrapy æ¥è¯•è¯•å§ã€‚
	![](http://uninote.com.cn/docs/1079089832/__pic/s4I9pqeq.png)

## ç¬¬äºŒæ­¥ï¼Œä½¿ç”¨scrapyæ¥åˆ›å»ºä½ çš„é¡¹ç›®
1. è¾“å…¥å‘½ä»¤`scrapy startproject scrapyDemo `, æ¥åˆ›å»ºä¸€ä¸ªçˆ¬è™«é¡¹ç›®
```
	liaochengdeMacBook-Pro:scrapy liaocheng$ scrapy startproject scrapyDemo
	New Scrapy project 'scrapyDemo', using template directory '/usr/local/lib/python3.7/site-packages/scrapy/templates/project', created in:
		/Users/liaocheng/script/scrapy/scrapyDemo

	You can start your first spider with:
		cd scrapyDemo
		scrapy genspider example example.com
	liaochengdeMacBook-Pro:scrapy liaocheng$ 
```
2. ä½¿ç”¨genspideræ¥ç”Ÿæˆä¸€ä¸ªåŸºç¡€çš„spider,ä½¿ç”¨å‘½ä»¤`scrapy genspider demo juejin.im`ï¼Œ åé¢è¿™ä¸ªç½‘å€æ˜¯ä½ è¦çˆ¬çš„ç½‘ç«™,æˆ‘ä»¬å…ˆçˆ¬è‡ªå·±å®¶çš„ğŸ˜‚
```
liaochengdeMacBook-Pro:scrapy liaocheng$ scrapy genspider demo juejin.im
Created spider 'demo' using template 'basic'
liaochengdeMacBook-Pro:scrapy liaocheng$ 
```
3. æŸ¥çœ‹ç”Ÿæˆçš„ç›®å½•ç»“æ„
![](http://uninote.com.cn/docs/1079089832/__pic/S7fK0VAz.png)

## ç¬¬ä¸‰æ­¥ï¼Œæ‰“å¼€é¡¹ç›®ï¼Œå¼€å§‹ç¼–ç 
1. æŸ¥çœ‹ç”Ÿæˆçš„çš„demo.pyçš„å†…å®¹
```
# -*- coding: utf-8 -*-
import scrapy
class DemoSpider(scrapy.Spider):
		name = 'demo'  ## çˆ¬è™«çš„åå­—
		allowed_domains = ['juejin.im']  ## éœ€è¦è¿‡æ»¤çš„åŸŸåï¼Œä¹Ÿå°±æ˜¯åªçˆ¬è¿™ä¸ªç½‘å€ä¸‹é¢çš„å†…å®¹
		start_urls = ['http://juejin.im/']  ## åˆå§‹urlé“¾æ¥
	
    def parse(self, response):  ## å¦‚æœæ–°å»ºçš„spiderå¿…é¡»å®ç°è¿™ä¸ªæ–¹æ³•
        pass
```
